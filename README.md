# Erlemar.github.io

1. Classification problems.
[Titanic: Machine Learning from Disaster](http://nbviewer.jupyter.org/github/Erlemar/Erlemar.github.io/blob/master/Notebooks/Titanic.ipynb) is a knowledge competition on Kaggle. Many people started practicing in machine learning with this competition, so did I. This is a binary classification problem: based on information about Titanic passengers we predict whether they survived or not. General description and data are available on [Kaggle](https://www.kaggle.com/c/titanic).

[Otto Group Product Classification Challenge](http://nbviewer.jupyter.org/github/Erlemar/Erlemar.github.io/blob/master/Notebooks/Otto_Group.ipynb) is a knowledge competition on Kaggle. This is a multiple classification problem. Based on information about products we predict to which category they belong. General description and data are available on [Kaggle](https://www.kaggle.com/c/otto-group-product-classification-challenge).

2. Regression problems.
[House Prices: Advanced Regression Techniques](http://nbviewer.jupyter.org/github/Erlemar/Erlemar.github.io/blob/master/Notebooks/House prices.ipynb) is a knowledge competition on Kaggle. This is a regression problem: based on information about houses we predict their prices. General description and data are available on [Kaggle](https://www.kaggle.com/c/house-prices-advanced-regression-techniques).

3. Natural language processing.
[Bag of Words Meets Bags of Popcorn](http://nbviewer.jupyter.org/github/Erlemar/Erlemar.github.io/blob/master/Notebooks/Bag_of_Words.ipynb) is a sentimental analysis problem. Based on texts of reviews we predict whether they are positive or negative. General description and data are available on [Kaggle](https://www.kaggle.com/c/word2vec-nlp-tutorial).